---
title             : "A Note on Using Systems of Orders to Capture Theoretical Constraint in Psychological Science"
shorttitle        : "Theory, Orders, & Bayes"

author: 
  - name          : "Julia M. Haaf"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "210 McAlester Hall, Columbia, MO, USA, 65203"
    email         : "jhaaf@mail.missouri.edu"
  - name          : "Fayette Klaassen"
    affiliation   : "2"
  - name          : "Jeffrey N. Rouder"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "University of Missouri"
  - id            : "2"
    institution   : "Utrecht University"
  - id            : "3"
    institution   : "University of California, Irvine"

author_note: >
  This paper was written in RMarkdown with code for data analysis integrated into the text. The Markdown script is open and freely available at [github.com/PerceptionAndCognitionLab/bf-order](https://github.com/PerceptionAndCognitionLab/bf-order). The data used here are not original. We make these freely available with permission of the original authors at [github.com/PerceptionCognitionLab/data0/tree/master/lexDec-dist5](https://github.com/PerceptionCognitionLab/data0/tree/master/lexDec-dist5). Fayette Klaassen was supported by a grant from The Netherlands Organisation for Scientific Research (NWO): NWO 406-12-001.

note: Version 3, 03/2018. This paper has not been peer reviewed.

abstract: "Most theories in the social sciences are verbal and provide ordinal-level predictions for data.  For example, a theory might predict that performance is better in one condition than another, but not by how much.  One way of gaining additional specificity is to posit multiple ordinal constraints simultaneously. For example a theory might predict an effect in one condition, a larger effect in another, and none in a third.  We call such simultaneous constraints a 'system of orders' and show how common theoretical positions lead naturally to system-of-order predictions.  We adopt a Bayesian model comparison approach to assess evidence for multiple, simultaneous order constraints, a difficult endeavor in a frequentist framework.  The result is a statistical system custom tuned for the way social scientists conceptualize theory that is more intuitive and informative than current linear-model approaches." 
  
keywords          : "Theory specification, Order constrained inference, Bayesian Inference"

bibliography      : ["lab.bib"]

header-includes   :
   - \usepackage{bm}
   - \usepackage{pcl}
   - \usepackage{amsmath}
   - \usepackage{setspace}
   - \usepackage{mathtools}

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : false

lang              : "english"
class             : jou
output            : papaja::apa6_pdf
csl               : apa6.csl
---

```{r settings, warning=F, message=F}
#load required packages
library(Hmisc)
library(BayesFactor)
library(MCMCpack)
library("spatialfil")
library("ggplot2")
library("papaja")
library("msm")
library("shape")
library("mvtnorm")
library("tmvtnorm")
library("cowplot")
library("gridExtra")
library('diagram')
```


 <!-- **Significance Statement**: Amid the turmoil in the social-science methodology, hypothesis testing as an intellectual activity has come under scrutiny.  Here, we note that most theories in the social sciences are verbal and provide ordinal-level predictions.  Meaningful constraint is gained by imposing multiple ordinal-level predictions simultaneously.  We propose that statistics be adapted to address whether different competing systems of order constraints best describe the structure in data.  We develop Bayes factors for the approach, and show how this approach of casting theory as orders leads to more insightful hypothesis testing. -->

<!-- \setlength{\parindent}{0.3in} -->


At the core of science is the ability to use data to inform theoretical positions.
In psychological science, these theoretical positions are often stated verbally and often lead to ordinal predictions for data.  Consider the proposition that reading is fast, obligatory, and automatic [@Kahneman:1973].  One ordinal implication of this theoretical statement is the usual Stroop effect [@Stroop:1935] where the colors of color terms (e.g. "red") are identified more quickly when they are congruent with the word identity (the word "red" written in red) than when they are incongruent with the identity (the word "green" written in red).

Psychologists often assess these ordinal predictions with a $t$-test, and the hypotheses underlying a one-sided $t$-test are direct tests of ordinal relations.  For example, a $t$-test can be used to state whether there is a Stroop effect (congruent identified on average more quickly than incongruent) or not.  One problem with the ordinal approach, however, is what we may call *intellectual inefficiency*.  By positing coarse verbal theory that provides for only modest constraints on the data, we are neither risking nor learning much from the data.

An alternative approach is to focus on more complex models that seemingly provide greater constraints on data. 
Some of these models go by *psychological process models*, and they describe in more detail the processes and representations used in cognition. 
Examples of process models are sequential sampling models and race models [@Townsend:Ashby:1983; @Smith:2000; @Lewandowsky:Farrell:2011; @Lee:Wagenmakers:2013; @Logan:1988]. 
Some researchers may argue that process models make metric predictions, and therefore provide for a more efficient analysis of data. 
We tend to disagree, however. 
While not a hard-and-fast rule, we find that metric predictions from psychological process models often reflect free parameters rather than deep structural commitments.

Take, for example, Cohen, Dunbar, & McClelland's [-@Cohen:etal:1990] neural network model of the Stroop effect. 
The metric value of the size of the effect reflects scaling parameters that convert network cycles to a time scale. 
The same type of free-parameter explanation holds say for a diffusion model account of the flanker task [@Pe:etal:2013]. 
In fact, we know of no theory that predicts the size of the Stroop effect be it 4 milliseconds or 4 seconds before the data are collected. 
In our view, even for complex models, there are few if any *a priori* metric predictions about psychological phenomena.

The question, then, is how shall psychological scientists gain more constraint in predictions?  We advocate that, instead of focusing on the prediction of the size of an effect, researchers should honor the verbal theoretical tradition by focusing on many ordinal constraints simultaneously. When many ordinal constraints are considered simultaneously, we may call them a *system of order constraints*.  Here are two examples of such systems:

## Example 1: Symbolic Distance 

@Moyer:Landauer:1967 developed a task where the observer decides if a presented digit is greater than five or less than five.  The presented digit is either 2, 3, 4, 6, 7, or 8.  Participants are highly accurate, and the dependent variable of interest is the time to make the comparison.  The main question of interest is how does the time vary as a function of the digit, and in particular, does this time increase or decrease as the digit is further from five.  Consider the following three theories, corresponding to three different sets of simultaneous orders: 

*Analog-Representation Theory* posits that numbers are stored in an analog system as a uni-dimensional quantity much like length [@Gallistel:Gelman:1992].  Just as comparing similar lengths is slower than disparate ones, this theory predicts that $\mu_4>\mu_3>\mu_2$ and $\mu_6>\mu_7>\mu_8$, where $\mu_i$ is the true mean response time for the $i$th digit. This ordering is shown in Figure\ \@ref(fig:order)A.  The symbol "$>$" represents the relation "is faster than."

*Propositional Representation Theory* posits that numbers are represented as semantic propositions, much like in a computer.  Accordingly, there should be no effect for distance-from-five.This prediction leads to the equalities $\mu_2=\mu_3=\mu_4$ and $\mu_6=\mu_7=\mu_8$.  We avoid specifying all six condition means are equal in case there is a speed difference across the "less than" and "greater than" response.  These equalities are represented in Figure\ \@ref(fig:order)B.  Unconnected nodes have no relation; so even though the node "3" is above node "6", there is no implied ordering because there is no line connecting the nodes.  

*Priming $+$ Spreading Activation Theory* posits that familiar or anticipated items are responded to more quickly, that is, they are primed.  Because participants need to keep the value of 5 in mind as part of the task demands, similar numbers are primed and responded to more quickly.  Assuming a semantic spreading activation network [@Collins:Loftus:1975], numbers closer to five receive greater priming.  Hence, this theory predicts $\mu_2>\mu_3>\mu_4$ and $\mu_8>\mu_7>\mu_6$.  This ordering is shown in Figure\ \@ref(fig:order)C; it is the reverse of that in Figure\ \@ref(fig:order)A.

Note that the orders are weak (they may include equalities) and partial (not all nodes have to be connected with each other node).  Figure\ \@ref(fig:order)D further illustrates this property.  Here there are six cells, and there is an ordering where Cell 1 is greater than Cells 2, 3, 4, 5, which in turn are greater than Cell 6.  There are equalities, Cells 2 and 3 are equal as are Cells 4 and 5. And there is partiality---there are no relations between select cells such as Cells 2 and 4.  Partial weak orders are sufficiently general to include no order constraints, as shown in Figure\ \@ref(fig:order)E.  *A system of order constraints is the conjunction and disjunction of several partial weak orders*.

```{r order, warning=FALSE, fig.env = "figure", fig.width= 8, fig.height=9, fig.cap="Examples of Orders. \\textbf{A.} Analog representation in the symbolic distance task implies response times decrease with distance from five.  \\textbf{B.} Propositional representation implies no response-time effects of distance.  \\textbf{C.} The priming account implies response times increase with distance from five. \\textbf{D.} Example of a partial weak order for six cells.  \\textbf{E.} A partial order may be unconstrained.  \\textbf{F.} Order constraints where all people show a true Stroop effect.  \\textbf{G.} An example of an order where some people have truly reversed Stroop effects (incongruent colors are identified faster than congruent ones)."}
source('R-scripts/fig1.R')
```

## Example 2: Does Everybody?

In the above example, the focus is on the ordering of true population means, say whether the true mean response time for one condition is faster, slower, or the same as for another.  Yet, the true mean across a population is a fairly removed abstraction, especially for the study of psychology.  As an alternative we may ask about ordinal constraints that are preserved across all participants.  We call this the *does everybody* question.  Does everybody plausibly Stroop in the same direction, or are there some people who truly name incongruent colors faster than congruent ones?  Does everybody plausibly detect loud tones more quickly than soft ones, or are there some people who truly detect soft tones more quickly than loud ones?  Do all people plausibly throw a ball further with their right hand, or are there some people who truly throw a ball further with their left?  

It is important to note that the focus is on true effects rather than sample scores.  Even when the true effects of everybody in a population are the same, we may observe some people who have scores that reverse the phenomena-of-interest due to sample noise.  The posed questions are about what happens after sample noise is accounted for.  Is it plausible that all individuals have true effects in the same direction, or, alternatively, is there evidence that some have true effects in the reverse direction.

If all people show an effect in the same direction, we may consider this behavior as lawful, automatic, perhaps biological, and largely outside of human variation.  If not, say if some people have effects in one direction and others have them reversed, we would examine theories with multiple processes, perhaps with some volitional control.  Moreover, the next set of questions would be to see whether the direction of effects is correlated with other characteristics, skills, or abilities. 

This question can be addressed by aggregating multiple individual analyses [@Klaassen:etal:2017].
Alternatively, @Haaf:Rouder:2017 propose a hierarchical approach.  The authors asked whether all readers truly identify congruent colors more quickly than incongruent ones, or alternatively, if there exist some readers who are Stroop reversed where they truly identify incongruent colors faster than congruent ones.  Our setup may be expressed by the system in Figure\ \@ref(fig:order)F.  The "everybody Stroops" model is shown as a consistency of ordering across all individuals; the negation is that some people, or at least one person, truly have reversed Stroop effects, and an example of this negation is shown in Figure\ \@ref(fig:order)G. 

# Statistical Development

Encoding theories as systems of ordinal constraints raises a set of statistical considerations---how may evidence from data for competing systems be assessed.  This assessment not only requires stating positive evidence for ordinal and inequality constraints, but doing so across many of them simultaneously in both conjunctive and disjunctive relations.  To the best of our knowledge, a general frequentist solution is not known [cf. @Robertson:etal:1988; @Silvapulle:Sen:2011].  Fortunately, Bayesian inference with inequality constraints is conceptually straightforward  [@Gelfand:etal:1992].   Here we follow the work of Klugkist and Hoijtink and colleagues who instantiate collections of equality and order constraints on linear model parameters [@Mulder:etal:2009; @Klugkist:etal:2005; @Klugkist:Hoijtink:2007].  Comparing systems in the Klugkist and Hoijtink framework becomes a matter of comparing the relative strength of evidence from the data for competing models.  These relative strengths may be quantified with Bayes factors [@Jeffreys:1961], which themselves are the direct consequence of updating beliefs about models with Bayes' rule.  @Hoijtink:etal:2008 provides a computationally convenient approach, further elaborated in @Hoijtink:2012.  We use the work of @Haaf:Rouder:2017 to extend this approach  for "does everyone" questions.

# Models for Orders: The Symbolic-Distance Effect Example

```{r modelplot-prep, child = "R-scripts/modelFigure.Rmd"}
```

We demonstrate Bayesian inference on systems of ordinal constraints for the symbolic-distance effect example.  @Rouder:etal:2005a ran a standard symbolic distance experiment to assess how response times change with symbolic distance.  Here, we consider the three order systems in Figure\ \@ref(fig:order)A-C: The Analog-Representation theory, the Propositional-Representation theory, and the Priming $+$ Spreading-Activation theory. Moreover, we consider whether all participants have the same ordering.  Let $Y_{ijk}$ denote the response time for the $i$th participant in the $j$th digit condition ($j=2,3,4,6,7,8$), and for the $k$th replicate:
\[Y_{ijk}|\nu_{ij},\sigma^2 \stackrel{ind}{\sim}\mbox{Normal}(\nu_{ij},\sigma^2),\]

where $\nu_{ij}$ is the $i$th person's true mean response time for the $j$th condition, and $\sigma^2$ is the trial-by-trial variation.
To represent the theories it is useful to reparameterize the above model into relative differences between condition means for each individual. The following appears complicated, but it is just a matter of defining the relevant contrasts within a linear model using dummy variables. Let $\Delta_{im}$ be $m$th relative difference for the $i$th person. There are four differences implied by the theories defined as follows: $\Delta_{i1}=\nu_{i3}-\nu_{i2}$, $\Delta_{i2}=\nu_{i4}-\nu_{i3}$, $\Delta_{i3}=\nu_{i6}-\nu_{i7}$, and $\Delta_{i4}=\nu_{i7}-\nu_{i8}$. With these differences, the cell means $\nu_{ij}$ are given as
\[
\nu_{ij} = \left(\nu_{i3} - x_{2j}\Delta_{i1} + x_{4j}\Delta_{i2}\right)^{s_j} + \left(\nu_{i7} - x_{8j}\Delta_{i4} + x_{6j}\Delta_{i3}\right)^{1-s_j},
\]
 where $s_j=1$ if the digit condition $j<5$, and $s_j=0$ otherwise; and $x_{j'j}=1$ if $j'$ indicates the current digit condition, $j$. 

With this reparameterization models may be placed on the relative differences, $\Delta_{im}$. These differences are defined so that they are a subtraction of a digit further from 5 from a digit that is closer to 5.  Hence, positive values of $\Delta_{im}$ are consistent with the Analog-Representation theory where response times are larger for digits closer to 5.  

```{r modelplot, fig.cap= "Models (left) and predictions (right) for the symbolic distance effect. Darker areas represent higher plausibility of $\\Delta_{im}$ before the data are collected.  Models are conditional on set values of $\\mu_m=0$ms and $\\eta=90$ms. Predictions take into account sampling noise and the correlation reflects the priors placed on $\\mu_m$ and $\\eta^2$. The red point represents a hypothetical observed data point for two individuals. The hypothetical data point is best predicted by the Analog-Representaion model.", fig.height=8, fig.asp= 1.8}
plot_grid(plots[[1]]
          , plots[[2]]
          , plots[[3]]
          , plots[[4]]
          , plots[[5]]
          , plots[[6]]
          , plots[[7]]
          , plots[[8]]
          , ncol = 2
          , rel_widths = c(.495, .505)
          , labels="AUTO"
          , label_x = rep(c(.03, -.03), 4)
          , label_fontface = "plain"
          )
```


The theories then correspond to the following constraints: 1. The Analog-Representation theory holds for the $i$th individual if $\Delta_{im}>0$ for each $m$. 2. The Priming $+$ Spreading-Activation theory holds for the $i$th individual if $\Delta_{im}<0$ for each $m$. 3. The Propositional-Representation model holds for the $i$th individual if $\Delta_{im}=0$ for each $m$.
 
In the next step, we write these constraints as formalized models on the collection of individuals' relative differences.  Model $\calM_0$ instantiates the statement that everybody uses propositional representation. It is given by
$$
\calM_0: \quad \Delta_{im}=0.
$$

Figure\ \@ref(fig:modelplot)A shows a graphical depiction of the Propositional-Representation model.  The $x$-axis shows the true effect for one participant for the $m$th difference, $\Delta_{1m}$; the $y$-axis shows the true effect for a second participant, $\Delta_{2m}$.  The only point with mass is $(0,0)$ showing that each participants' relative differences between digit conditions must be identically zero.

Model $\calM_+$ instantiates the statement that everybody uses analog representation, and it is given by:
$$
\calM_+: \quad \Delta_{im}|\mu_m,\eta^2 \sim \mbox{Normal}_+(\mu_m,\eta^2),
$$

where Normal$_+$ is a normal distribution truncated from below at zero, $\mu_m$ is the population mean of the $m$th digit condition difference, and $\eta^2$ is the variability of individuals around this mean. Figure\ \@ref(fig:modelplot)C depicts this model for two participants (for set values of $\mu_m$ and $\eta^2$).  For both participants, only positive values have mass. 

Model $\calM_-$ instantiates the statement that everybody uses priming $+$ spreading activation, and it is given by:
$$
\calM_-: \quad \Delta_{im}|\mu_m,\eta^2 \sim \mbox{Normal}_-(\mu_m,\eta^2),
$$
where Normal$_-$ is a normal truncated from above at zero.  Figure\ \@ref(fig:modelplot)E depicts this model for two participants.  For both participants only negative values have mass.

Of course, it may be that not everyone uses the same number representation.  We decided to implement a "none-of-the-above" model by placing no ordinal constraints on the relative differences.  This model is termed the unconstrained model and is denoted $\calM_u$:

$$
\calM_u: \quad \Delta_{im}|\mu_m,\eta^2 \sim \mbox{Normal}(\mu_m,\eta^2).
$$

If this model is strongly preferred, the interpretation is that none of the everybody-does models are appropriate. Consequently, we may conclude different people use different representations. Figure\ \@ref(fig:modelplot)G illustrates this model for two participants. Here, the participants' effects are not constrained to any of the quadrants. 

Prior specifications are needed for $\sigma^2$, $\mu_m$, $\eta^2$, $\nu_3$ and $\nu_7$.  We take a $g$-prior approach as discussed in @Haaf:Rouder:2017, and the prior specifications for this application are provided in the Appendix.

In Figure\ \@ref(fig:modelplot), we show the model specification for any two participants on any one difference contrast (for any one value of $m$).  For the symbolic-distance experiment by @Rouder:etal:2005a, however, four difference contrasts are specified, and 52 individuals participated in the experiment. The figure therefore understates the dramatic differences in constraint between the models.  The constraints provided by the models must hold across all people and across all difference contrasts simultaneously.  

# Bayesian Model Comparison

We use Bayes factors to assess the relative evidence for the above models.  The Bayes factor for any two models, Models $\calM_a$ and $\calM_b$, is given by:
\[
B_{ab} = \frac{P(\bfY|\calM_a)}{P(\bfY|\calM_b)},
\]
where $\bfY$ is the collection of all observations.  The numerator and denominator are marginal probabilities of the data under the respective models, and these quantities are best thought of as the model predictions of data.  The right column of Figure\ \@ref(fig:modelplot) shows the predictions on observed relative differences for the four models applied here.  One aspect of these predictions that is not obvious is the correlation across participants.  This correlation comes from the hierarchical structure in these models, and is a direct result of variability of the population mean, $\mu_m$, as compared to the between-person variability, $\eta^2$.  A formal discussion of both the Bayes factor computations and the hierarchical structure of the models is provided in @Haaf:Rouder:2017.

Once the predictions are known, model comparison is simple.  All we need to do is note where the data fall [cf. complexity and fit in @Hoijtink:2012].  The red dots in the right column denote hypothetical observed sample differences, $\hat{\Delta}_{im}$, for both participants.  As can be seen, this datum is best predicted by the Analog-Representation model.  In computation, this comes down to comparing samples from the prior (predictions) to samples from the posterior (where the data fall).

# Results

```{r setup, include=FALSE, eval = T}
knitr::knit_hooks$set(plot = knitr::hook_plot_tex)
```

```{r ld5, warning=FALSE, fig.width= 9, fig.asp=.35, fig.env="figure*", fig.cap="Symbolic Distance effects: \\textbf{A.} Condition means show a pattern indicative of analog representation.  \\textbf{B.} Observed successive differences for all individuals.  Positive values are indicative of analog representation. \\textbf{C.} Model estimates of successive differences from the unconstrained model.  There is much shrinkage indicating that much of the noise in the observed values is due to trial-by-trial noise."}
set.seed(123)
source('R-scripts/ld5.R')
```

The results of the analysis of Rouder et al.'s [-@Rouder:etal:2005a] data are shown in Figure\ \@ref(fig:ld5).  Panel A depicts sample means across people as a function of digit condition, and it is obvious that, at an aggregated level, the Analog-Representation explanation is preferred.  The next question is whether all participants use this analog representation.  Panel B shows the participant-specific sample means, $\hat{\Delta}_{im}$ for all people and differences.  As can be seen, there is a lot of variability. The variability in this example shows how difficult it is to answer the question of whether everybody uses an analog representation by just inspecting sample effects. A model-based analysis is needed.

Panel C shows model-based estimates from the unconstrained model.  Here, the hierarchical structure in the prior results in the regularization of difference contrasts indicating that much of the variability in the sample means in Panel B reflects trial-to-trial noise.  This type of regularization depends on the number of observations within a person, and it is common in within-subject designs, and it shows a key practical value of hierarchical models in analysis [@Efron:Morris:1977; @Gelman:Carlin:2017; @Rouder:etal:2005a].  By inspection, all but one of the estimates are above zero.  As a consequence, it may be tempting to use these estimates as evidence for the everybody-has-analog-representation constraint.  Yet, much more caution is needed here. The individual estimates provided by the unconstrained model are not independent over persons, and as a consequence, observing which are above and below zero may be deceiving.  For these data, estimation is useful, but it does not address the question of interest.

This question may be answered by computing Bayes factors for the four models. First, we compare the three *everybody does* models.  The clear winner is the Analog-Representation model, and it beats the Propositional-Representation model by over $10^{55}$-to-1.  The Priming $+$ Spreading-Activation model performs so poorly that its decrement is outside of our numerical precision, and it is at least 100 orders worse than the Analog-Representation model.  Second, we may also compare the Analog-Representation model to the unconstrained model, and the Bayes factor is 1.4-to-1 in favor of the former.  

Practically, the data provides equivalent support for everybody-has-analog-representation as it does for the unconstrained model. Note that this unconstrained model was used as a none-of-the-above option. It does not exclude the options of the other models, but it is only preferred if none of the other models predicts the data well enough.  We may use the estimates from the unconstrained model to diagnose the source of the equivalence.  As can be seen in the sample means in Figure\ \@ref(fig:ld5)B, the overall trend is for smaller values for the first and fourth difference ($\hat{\Delta}_{i1}$ and $\hat{\Delta}_{i4}$), and, concordantly, many participants have negative observed values for these contrasts.  In retrospect, this behavior is quite reasonable as there must be a fall off in the distance-from-five effect with increasing distances.  For example, large numbers, say 21 and 22, are probably both classified as greater than five with the same speed.  Indeed, this type of fall-off is prevalent with physical uni-dimensional quantities such as brightness and tone volumes [@Luce:1986].  For future application, a more refined instantiation of the Analog-Representation model that incorporates this expected decrease may be useful.  

We are sanguine about the utility and parsimony of the *everybody does* models.  The data rule out the Propositional-Representation and Priming $+$ Spreading-Activation models while retaining the plausibility that everybody uses analog representation in this task.

# Conclusions and Limitations

Given the coarse state of theory in the social sciences, a profitable avenue for gaining constraint and falsifiability is to propose multiple ordinal constraints simultaneously.  Here, we develop principled and straightforward Bayesian inference that is broadly applicable and scales up well to questions such as "does everyone," "do some," or "do none."  It is our hope that such tools will motivate researchers to better specify theory as systems of constraints.  

In the beginning of this paper, we noted that models with metric relations, process models, rarely make metric predictions on data.  Instead, much like physical models, they yield conservations.  For example, the diffusion model of perception [@Ratcliff:Rouder:1998] predicts that speed-vs-accuracy instructions should affect a bound parameter and not a stimulus-strength parameter (drift rate).  These predictions form a system of orders that may be analyzed with the aforementioned developments.

There are perhaps three limitations of the current approach: 1. the use of parametric models, 2. the need for prior specifications, and 3. the lack of implementation of these methods in popular software platforms.  We take these in turn.

The current modeling approach is to place ordinal constraints on mean parameters in linear models with normally-distributed noise [@Klugkist:etal:2005].  One may wonder about the sensitivity of inference to the normal specification.  In linear models, effects are assumed to shift the noise distribution without changing its scale or shape. The general consensus is that these specifications are not too problematic in classical inference [@Hays:1994].  In our experience, both from simulation and from practice [see, for example, @Thiele:etal:2017; @Rouder:etal:2017b; @Haaf:Rouder:submitted], the effects we explore are so small relative to trial noise that the shifted normal is a fine approximation.  

The more concerning limitation is the need to specify prior distributions with tuning settings.  The main parameters of concern are those that differentiate the models, and in the case above, these are $\mu_m$ and $\eta^2$.  The prior on these parameters define *a priori* expectations about the overall size of an effect and *a priori* expectations about between-person variability around this overall mean.  The choice of these tuning parameters is a substantive choice rather than a statistical one, and researchers who are substantive experts in their domain should be unafraid to add value here.  We set ours as follows:  We reasoned that any distance-from-five effect is roughly on the order of 50 ms and between-person variability is roughly on the order of 30 ms.  This is not to say that $\mu_m$ and $\eta^2$ are these values, but they come from distributions that reflect these settings.   Our advise is that researchers should use a range of scale settings they find reasonable and track how inference changes across these settings.  Detailed discussion and examples of this approach may be found in @Rouder:etal:2016b and @Haaf:Rouder:2017.

The final limitation is that the current analyses are not yet available in popular packages.  Perhaps the easiest software package to use for computing Bayes factor is `JASP` [@Love:etal:2015].  This package was reverse engineered to look and feel like `SPSS`, and users familiar with with `SPSS` can use `JASP` easily.  `JASP` has some inequality constraints implemented, but is not yet set up to analyze systems of order constraints more generally.  Users of `R` can get the same functionality out of the  `BayesFactor` package [@Morey:Rouder:BayesFactorPackage].  Less well known is the package `BAIN` [@Gu:etal:inpress], which is also an `R` package specifically designed for computing Bayes factors with equality and inequality constraints.  While the current software situation is fluid and there are turn-key solutions for only a handful of models, we suspect that easy-to-use packages which address a full range of order constraints will be available soon.

# Appendix

Prior specifications are needed for the parameters $\sigma^2$, the trial-by-trial variation, $\nu_{i3}$ and $\nu_{i7}$, the mean response times for the two contrasting conditions, $\mu_m$, the means of difference contrasts, and $\eta^2$, the variance of difference contrasts. 

The full Bayesian specification of the model comes from @Haaf:Rouder:2017. Priors on $\sigma^2$, $\nu_{i3}$ and $\nu_{i7}$ are fairly broad and do not affect model comparison. The crucial prior specifications are on $\mu_m$ and $\eta^2$, and we place mildly informative priors on these parameters following Zellner's $g$-prior specification [@Zellner:1986]. Let $g_\Delta=\eta^2/\sigma^2$. Then:
\[
\begin{aligned}
\mu_m & \sim \mbox{Normal}(0,g_{\mu}\sigma^2),\\
g_\Delta & \sim \mbox{inverse-$\chi^2$}(1,r^2_\Delta),\\
g_\mu & \sim \mbox{inverse-$\chi^2$}(1,r^2_\mu),
\end{aligned}
\]
where inverse-$\chi^2$(a,b) is a scaled inverse chi-squared distribution with $a$ degrees-of-freedom and a scale of $b$ [see @Gelman:etal:2004]. The following settings are used: $r_\Delta= .1$, and $r_{\mu}=.16$.

It is important to know how these substantive choices for setting $r_\Delta$ and $r_{\mu}$ affect model comparison results.  We address this issue in Conclusions and Limitations.

\newpage

#References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}